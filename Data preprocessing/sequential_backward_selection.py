from sklearn.base import clone
# Construct a new unfitted estimator with the same parameters.Clone does a deep copy of the model in an estimator without
# actually copying attached data. It returns a new estimator with the same parameters that has not been fitted on any data.
from sklearn.metrics import accuracy_score
from sklearn.model_selection import train_test_split
import numpy as np
# combinations('ABCD', 2) ----> AB AC AD BC BD CD
from itertools import combinations

"""
Start with the full feature set Xd, where d is the number of features.
For each feature x ∈ Xk (current feature set), evaluate the criterion J(Xk−x).
Remove the feature x that results in the smallest performance loss. (Basically the one with the highest accuracy score since the diff would be lower)
Repeat until the desired number of features remain.
"""


class SBS:
    def __init__(self, estimator, k_features, scoring=accuracy_score, test_size=0.25, random_state=1):
        self.scoring = scoring
        self.estimator = clone(estimator)
        self.k_features = k_features
        self.test_size = test_size
        self.random_state = random_state

    def fit(self, X, y):
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=self.test_size, random_state=self.random_state)

        dim = X_train.shape[1]
        self.indices_ = tuple(range(dim))
        self.subsets_ = [self.indices_]
        score = self._calc_score(
            X_train, y_train, X_test, y_test, self.indices_)
        self.scores_ = [score]

        while dim > self.k_features:
            scores = []
            subsets = []

            for p in combinations(self.indices_, r=dim - 1):
                score = self._calc_score(X_train, y_train, X_test, y_test, p)
                scores.append(scores)
                subsets.append(p)

            best = np.argmax(scores)
            self.indices_ = subsets[best]
            self.subsets_.append(self.indices_)
            dim -= 1

            self.scores_.append(scores[best])

        self.k_score_ = self.scores_[-1]

        return self

    def transform(self, X):
        return X[:, self.indices_]

    def _calc_score(self, X_train, y_train, X_test, y_test, indices):
        self.estimator.fit(X_train[:, indices], y_train)
        y_pred = self.estimator.predict(X_test[:, indices])
        score = self.scoring(y_test, y_pred)
        return score
